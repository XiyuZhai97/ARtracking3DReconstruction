{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW note"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calib\n",
    "### fix size & fix focal length ➡️ .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import CalibrationHelpers as calib\n",
    "import glob\n",
    "import time\n",
    "directory = ''\n",
    "imagesp = glob.glob(directory+'/*.png')\n",
    "imagesj = glob.glob(directory+'/*.jpeg')\n",
    "res = 400\n",
    "for fname in imagesp + imagesj:\n",
    "    img = cv2.imread(fname)\n",
    "    #  downscale your image \n",
    "    img = cv2.resize(img,(RES,RES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 Compute relative pose between cameras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import Mobile3DRecon\n",
    "images = glob.glob('Mobile_Ref_data'+'/*.jpeg')\n",
    "savR = np.zeros((len(images), 3, 3))\n",
    "savT = np.zeros((len(images), 3))\n",
    "imgNum = 0\n",
    "intrinsics, distortion, new_intrinsics, roi = \\\n",
    "        calib.LoadCalibrationData('mobile_calib_data')\n",
    "RES = 400\n",
    "for fname in images:\n",
    "    # read the image\n",
    "    print(fname)\n",
    "    cap = cv2.imread(fname)\n",
    "    current_frame = cv2.resize(cap,(RES,RES))\n",
    "    ret, R, T = Mobile3DRecon.ComputePoseFromHomography(new_intrinsics,referencePoints,\n",
    "                                          imagePoints)\n",
    "    savR[imgNum] = R\n",
    "    savT[imgNum] = T\n",
    "    imgNum += 1\n",
    "    \n",
    "# Compute relative pose between cameras\n",
    "relR = np.zeros((len(images), 3, 3))\n",
    "relT = np.zeros((len(images), 3))\n",
    "fromimg = 0\n",
    "for i in range(imgNum - 1):\n",
    "    relR[i + 1] = np.matmul(savR[i + 1], savR[fromimg])\n",
    "    relT[i + 1] = savT[i + 1] - np.matmul(np.matmul(savR[i + 1], savR[fromimg].T), savT[fromimg])\n",
    "\n",
    "print(\"relR\", relR[1:])\n",
    "print(\"relT\", relT[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as spio\n",
    "spio.savemat(\"relR.mat\", relR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 Compute feature matches between images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('Mobile_Ref_data'+'/*.jpeg')\n",
    "# Load the reference image that we will try to detect in the webcam\n",
    "reference = cv2.imread(images[0],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 Use epipolar constraints to remove bad feature matches\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ARTrack3DReconstruction] *",
   "language": "python",
   "name": "conda-env-ARTrack3DReconstruction-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
